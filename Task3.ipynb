{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and Loading the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from rdflib import URIRef, Literal, Namespace\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "with open('graph.pkl', 'rb') as f:\n",
    "    g = pickle.load(f)\n",
    "\n",
    "\n",
    "# Define the ARXIV namespace\n",
    "ARXIV = Namespace(\"http://arxiv.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper ID: http://arxiv.org/1605.02688, PageRank Score: 0.0005306937790931203\n",
      "Paper ID: http://arxiv.org/1011.0352, PageRank Score: 0.0004946854805135188\n",
      "Paper ID: http://arxiv.org/1412.6980, PageRank Score: 0.0004745626324922854\n",
      "Paper ID: http://arxiv.org/quant-ph/9705052, PageRank Score: 0.0004000020722544104\n",
      "Paper ID: http://arxiv.org/1105.4464, PageRank Score: 0.0003678372466247783\n"
     ]
    }
   ],
   "source": [
    "# Function to convert RDF graph to NetworkX graph\n",
    "def rdf_to_nx(g):\n",
    "    nx_graph = nx.MultiDiGraph()\n",
    "    for s, p, o in g:\n",
    "        if isinstance(o, Literal):\n",
    "            continue  # skip literals\n",
    "        if p == ARXIV.cites:\n",
    "            nx_graph.add_edge(s, o)\n",
    "    return nx_graph\n",
    "\n",
    "# Convert RDF graph to NetworkX graph\n",
    "nx_graph = rdf_to_nx(g)\n",
    "\n",
    "# Compute PageRank\n",
    "pagerank_scores = nx.pagerank(nx_graph)\n",
    "\n",
    "# Get the paper IDs with highest PageRank scores\n",
    "top_papers = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the paper IDs with highest PageRank scores\n",
    "for paper, score in top_papers[:5]:\n",
    "    print(f'Paper ID: {paper}, PageRank Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: http://arxiv.org/1207.7235, Authority Score: 0.0010448481862151623\n",
      "Node: http://arxiv.org/1207.7214, Authority Score: 0.0010448481862151621\n",
      "Node: http://arxiv.org/1201.4330, Authority Score: 0.001020359768844416\n",
      "Node: http://arxiv.org/hep-ph/0404258, Authority Score: 0.0009996509720124253\n",
      "Node: http://arxiv.org/1712.09737, Authority Score: 0.0009996509720124247\n",
      "\n",
      "Node: http://arxiv.org/2009.00516, Hub Score: 0.8604648613325923\n",
      "Node: http://arxiv.org/2008.06494, Hub Score: 0.03426114842935148\n",
      "Node: http://arxiv.org/1805.00736, Hub Score: 0.019742846036246903\n",
      "Node: http://arxiv.org/2007.08542, Hub Score: 0.018594643479388797\n",
      "Node: http://arxiv.org/1802.09886, Hub Score: 0.018535168449002236\n"
     ]
    }
   ],
   "source": [
    "# Compute HITS scores\n",
    "hub_scores, authority_scores = nx.hits(nx_graph)\n",
    "\n",
    "# Get the nodes with the highest authority scores\n",
    "top_authorities = sorted(authority_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the nodes with the highest authority scores\n",
    "for node, score in top_authorities[:5]:\n",
    "    print(f'Node: {node}, Authority Score: {score}')\n",
    "\n",
    "print()\n",
    "\n",
    "top_hubs = sorted(hub_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for node, score in top_hubs[:5]:\n",
    "    print(f'Node: {node}, Hub Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvector Centrality Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper ID: http://arxiv.org/2009.00516, Eigenvector Centrality Score: 0.6946376053239083\n",
      "Paper ID: http://arxiv.org/Paper, Eigenvector Centrality Score: 0.1276862496329813\n",
      "Paper ID: http://arxiv.org/2008.06494, Eigenvector Centrality Score: 0.054003200883229796\n",
      "Paper ID: http://arxiv.org/1805.00736, Eigenvector Centrality Score: 0.04312412602596338\n",
      "Paper ID: http://arxiv.org/2012.07714, Eigenvector Centrality Score: 0.03892029018082451\n"
     ]
    }
   ],
   "source": [
    "# Convert RDF graph to NetworkX graph\n",
    "G = rdflib_to_networkx_digraph(g)\n",
    "\n",
    "# Get all nodes which are papers (URIs that start with http://arxiv.org/)\n",
    "paper_nodes = [n for n in G.nodes() if str(n).startswith(\"http://arxiv.org/\")]\n",
    "\n",
    "# Create a subgraph of G that includes only paper nodes and the edges between them\n",
    "G_paper_subgraph = G.subgraph(paper_nodes)\n",
    "\n",
    "# Remove parallel edges, if any, by converting DiGraph to a simple Graph \n",
    "G_paper_simple = nx.Graph(G_paper_subgraph)\n",
    "\n",
    "# Calculate eigenvector centrality\n",
    "centrality = nx.eigenvector_centrality_numpy(G_paper_simple)\n",
    "\n",
    "# Print the top 5 papers by eigenvector centrality\n",
    "sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for paper_id, centrality_score in sorted_centrality[:5]:\n",
    "    print(f'Paper ID: {paper_id}, Eigenvector Centrality Score: {centrality_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of  PageRank scores, Hub scores, and Eigenvector Centrality for each paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper ID: http://arxiv.org/2009.00516, Final Score: [0.66838086]\n",
      "Paper ID: http://arxiv.org/1605.02688, Final Score: [0.33351089]\n",
      "Paper ID: http://arxiv.org/1011.0352, Final Score: [0.29804897]\n",
      "Paper ID: http://arxiv.org/1412.6980, Final Score: [0.27853691]\n",
      "Paper ID: http://arxiv.org/quant-ph/9705052, Final Score: [0.20516886]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the scores using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pagerank_scores = {k: v for k, v in sorted(pagerank_scores.items(), key=lambda item: item[1])}\n",
    "hub_scores = {k: v for k, v in sorted(hub_scores.items(), key=lambda item: item[1])}\n",
    "centrality = {k: v for k, v in sorted(centrality.items(), key=lambda item: item[1])}\n",
    "\n",
    "scores = [pagerank_scores, hub_scores, centrality]\n",
    "normalized_scores = []\n",
    "\n",
    "for score in scores:\n",
    "    # Reshape the scores to fit the scaler\n",
    "    data = np.array(list(score.values())).reshape(-1, 1)\n",
    "    # Fit the scaler and transform the data\n",
    "    normalized = scaler.fit_transform(data)\n",
    "    # Map the normalized scores back to the paper ids\n",
    "    normalized_score = {k: v for k, v in zip(score.keys(), normalized)}\n",
    "    normalized_scores.append(normalized_score)\n",
    "\n",
    "# Calculate the final scores by averaging the normalized scores\n",
    "final_scores = {}\n",
    "weights = [1/3, 1/3, 1/3]  # weights for each score\n",
    "\n",
    "for paper_id in pagerank_scores.keys():\n",
    "    final_scores[paper_id] = sum(normalized_scores[i][paper_id]*weights[i] for i in range(3))\n",
    "\n",
    "# Sort the final scores and print the top 5 papers\n",
    "top_papers_final = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for paper, score in top_papers_final[:5]:\n",
    "    print(f'Paper ID: {paper}, Final Score: {score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
